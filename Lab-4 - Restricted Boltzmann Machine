import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report
from keras.layers import Input, Dense
from keras.models import Model


mnist = fetch_openml('mnist_784', version=1)
data = mnist['data'].values
labels = mnist['target'].astype(int).values


scaler = StandardScaler()
data_normalized = scaler.fit_transform(data)


X_train, X_test, y_train, y_test = train_test_split(data_normalized, labels, test_size=0.2, random_state=42)


input_dim = X_train.shape[1]
encoding_dim = 100  # Number of features to extract (hidden layer size)


input_layer = Input(shape=(input_dim,))
encoded = Dense(encoding_dim, activation='relu')(input_layer)
decoded = Dense(input_dim, activation='sigmoid')(encoded)

autoencoder = Model(input_layer, decoded)
encoder = Model(input_layer, encoded)

autoencoder.compile(optimizer='adam', loss='binary_crossentropy')


autoencoder.fit(X_train, X_train, epochs=10, batch_size=256, shuffle=True, validation_data=(X_test, X_test))


X_train_features = encoder.predict(X_train)
X_test_features = encoder.predict(X_test)


mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)
mlp_classifier.fit(X_train_features, y_train)


y_pred = mlp_classifier.predict(X_test_features)
print(classification_report(y_test, y_pred))


plt.figure(figsize=(10, 5))
for i in range(10):
    plt.subplot(2, 5, i+1)
    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')
    plt.title(f"Pred: {y_pred[i]} Actual: {y_test[i]}")
    plt.axis('off')
plt.show()
